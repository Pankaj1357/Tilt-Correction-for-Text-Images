{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center>Tilt Correction in Text Images </center></h1>\n",
    "<h2> Course Project : Image Processing EE 610 </h2>\n",
    "<p> Submitted By:- <ul> <li> Pankaj Singh (183079036)</li>\n",
    "    <li> Amit Lohan (183079033) </li>\n",
    "    <li> Devanshu Singh Gaharwar (16D070042)</li>\n",
    "    </ul>\n",
    " </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implementation Approach </h1>\n",
    "<img src=\"./data/extra/image_processing.jpg\" alt=\"image source missing\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STAGE 1 : Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = np.array(Image.open('./data/final.jpeg')) # reading the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> RGB to Gray scale conversion </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = input_image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # getting gray scale from RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 960)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(input_image)\n",
    "plt.title(\"Original Tilted Image\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2,2)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.title(\"Gray Scaled Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STAGE 2 : Low Pass filtering </h1>\n",
    "<p> We will use frequency domain Gaussian Blurring to suppress the high frequency content and smoothen out the image a bit to avoid unecessary edge detection. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to help with obtaining magnitude spectrum of fft and rescale the image for \n",
    "# display purposes.\n",
    "def rescale(x):\n",
    "    x = np.abs(x)\n",
    "    x = x - np.min(x)\n",
    "    x = (x * 255) / np.max(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a Gaussian low pass filter mask\n",
    "gaussian_LP_filter_mask = np.zeros((2700, 2700))\n",
    "D0 = 270\n",
    "m = gaussian_LP_filter_mask.shape[0]\n",
    "n = gaussian_LP_filter_mask.shape[1]\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        power = ((i -(m/2))**2 + (j -(n/2))**2) / (2 * D0**2)\n",
    "        gaussian_LP_filter_mask[i, j] = np.exp(-power)\n",
    "\n",
    "        \n",
    "gaussian_LP_filter_mask = gaussian_LP_filter_mask.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We obatained 2700 point FFT  to avoid wrap around errors as the orginal image size is\n",
    "(1280, 960) and did point wise multiplication of the obtained FFT with Gaussian filter mask\n",
    "created above. Then we took it's inverse FFT to get low pass Gaussian fitered image. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting image fft\n",
    "gray_image_fft = np.fft.fft2(gray, s=(2700, 2700), axes=(-2, -1), norm=None) \n",
    "\n",
    "# doing low pass filterin in frequency domain using Gaussian filter.\n",
    "filtered_image_fft = np.fft.fftshift(gray_image_fft) * gaussian_LP_filter_mask\n",
    "\n",
    "# Taking IFFT and obtaining low pass filtered Image.\n",
    "filtered_image = np.fft.ifft2(filtered_image_fft, s=None, axes=(-2, -1), norm=None)\n",
    "filtered_image = rescale(filtered_image)[:image.shape[0], :image.shape[1]].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualizations </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(skimage.exposure.adjust_gamma(rescale(np.fft.fftshift(gray_image_fft)), 0.20), cmap = 'gray')\n",
    "plt.title(\"Gray Scale Image in Frequency Domain\")\n",
    "\n",
    "ax = fig.add_subplot(1, 3,2)\n",
    "plt.imshow(gaussian_LP_filter_mask, cmap = 'gray')\n",
    "plt.title(\"Gaussina Low Pass Filter\")\n",
    "\n",
    "ax = fig.add_subplot(1, 3,3)\n",
    "plt.imshow(skimage.exposure.adjust_gamma(rescale(filtered_image_fft), 0.20), cmap = 'gray')\n",
    "plt.title(\"Gaussian Low Pass Filter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.title(\"Gray Scale Image\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2,2)\n",
    "plt.imshow(filtered_image, cmap = 'gray')\n",
    "plt.title(\"Gaussian Low Pass Filtered Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STAGE 3 : Edge detection using Canny Operator </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(filtered_image, 100, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(filtered_image, cmap = 'gray')\n",
    "plt.title(\"Gaussan Blurred Image\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2,2)\n",
    "plt.imshow(edges, cmap = 'gray')\n",
    "plt.title(\"Edges detected by Canny Operator\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STAGE 4 : Line Detection Using Hough Transform </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line_Detection:\n",
    "    \n",
    "    def __init__(self, edges):\n",
    "        self.edges = edges\n",
    "        \n",
    "    \n",
    "    def get_hough_lines(self, min_line_len, max_line_len):\n",
    "        lines = cv2.HoughLinesP(self.edges, 1, np.pi/180, 100,\n",
    "                                minLineLength=min_line_len, maxLineGap=max_line_len)\n",
    "        return lines\n",
    "    \n",
    "    \n",
    "    def draw_hough_lines(self, lines):\n",
    "        drawing = np.zeros(image.shape, np.uint8)\n",
    "        for line in lines: \n",
    "            a, b, a1, b1 = line[0]\n",
    "            cv2.line(drawing, (a,b), (a1, b1), (255, 255,255), 2)\n",
    "\n",
    "        return drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_detector = Line_Detection(edges)\n",
    "lines = line_detector.get_hough_lines(min_line_len=300, max_line_len=366)\n",
    "hough_lines = line_detector.draw_hough_lines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(hough_lines)\n",
    "plt.title(\"Lines detected By Hough Tansform\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2,1)\n",
    "plt.imshow(edges, cmap = 'gray')\n",
    "plt.title(\"Edges detected by Canny Operator\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STAGE 5 : Four Corner Points Detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corner_Detection:\n",
    "    \n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "           \n",
    "    def get_corner_points(self):\n",
    "        \n",
    "        toplx, toply = 10000, 10000\n",
    "        toprx, topry = -10000, 10000\n",
    "        botlx, botly = 10000, -10000\n",
    "        botrx, botry = -10000, -10000\n",
    "\n",
    "        for line in self.lines:              # First Point\n",
    "            arr = np.array(line).squeeze()\n",
    "            \n",
    "            x1, y1, x2, y2 = arr\n",
    "            \n",
    "            if -x1-y1>-toplx-toply:   ###  checking for min values of (x+y)\n",
    "                toplx, toply = x1, y1\n",
    "                \n",
    "            if -x2-y2>-toplx-toply:\n",
    "                toplx, toply = x2, y2\n",
    "                \n",
    "        for line in self.lines:                         # Second Point\n",
    "            arr = np.array(line).squeeze()\n",
    "            \n",
    "            x1, y1, x2, y2 = arr\n",
    "\n",
    "            if -y1+x1>toprx-topry:\n",
    "                toprx, topry= x1, y1\n",
    "\n",
    "            if -y2+x2>toprx-topry:\n",
    "                toprx, topry = x2, y2\n",
    "\n",
    "        for line in self.lines:                      # Third Point\n",
    "            arr = np.array(line).squeeze()\n",
    "            \n",
    "            x1, y1, x2, y2 = arr\n",
    "\n",
    "            if y1-x1>-botlx+botly:\n",
    "                botlx, botly = x1, y1\n",
    "\n",
    "            if y2-x2>-botlx+botly:\n",
    "                botlx, botly = x2, y2\n",
    "\n",
    "        for line in self.lines:                       # Fourth Point\n",
    "            arr = np.array(line).squeeze()\n",
    "            \n",
    "            x1, y1, x2, y2 = arr\n",
    "\n",
    "            if y1+x1>botrx+botry:\n",
    "                botrx, botry = x1, y1\n",
    "\n",
    "            if y2+x2>botrx+botry:\n",
    "                botrx, botry = x2, y2\n",
    "         \n",
    "        # return all points in a tuple\n",
    "        return (toplx, toply, toprx, topry, botlx, botly, botrx, botry)\n",
    "    \n",
    "    \n",
    "    def visualize_corner_points(self, img, detected_points, point_size):\n",
    "        toplx, toply, toprx, topry, botlx, botly, botrx, botry = detected_points\n",
    "        \n",
    "        cv2.circle(img,(toplx,toply), point_size, (0, 0, 255), -1)\n",
    "        cv2.circle(img,(toprx,topry), point_size, (255, 255, 255), -1)\n",
    "\n",
    "        cv2.circle(img,(botlx,botly), point_size, (0, 255, 0), -1)\n",
    "        cv2.circle(img,(botrx,botry), point_size, (255, 0, 255), -1)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_detector = Corner_Detection(lines)        #instantiating the Corner detection\n",
    "points = corner_detector.get_corner_points()     # getting the four detected corner points\n",
    "img = input_image.copy()\n",
    "plot_corner_points = corner_detector.visualize_corner_points(img, points, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(plot_corner_points)\n",
    "plt.title(\"Corner Points Detected\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2,1)\n",
    "plt.imshow(input_image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STAGE 6 : Perspective Transformation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerspectiveTransform:\n",
    "    def __init__(self, detected_points):\n",
    "        \n",
    "        self.detected_points = detected_points\n",
    "        \n",
    "    def get_rectangle(self):\n",
    "        toplx, toply, toprx, topry, botlx, botly, botrx, botry = self.detected_points\n",
    "        pts = np.array([(toplx,toply),(toprx,topry),(botlx,botly),(botrx,botry)])\n",
    "        \n",
    "        rectangle = np.zeros((4, 2), dtype = \"float32\")\n",
    "        \n",
    "        sum_row = pts.sum(axis = 1)\n",
    "        rectangle[0] = pts[np.argmin(sum_row)]\n",
    "        rectangle[2] = pts[np.argmax(sum_row)]\n",
    "        \n",
    "        diff_row = np.diff(pts, axis = 1)\n",
    "        rectangle[1] = pts[np.argmin(diff_row)]\n",
    "        rectangle[3] = pts[np.argmax(diff_row)]\n",
    "        \n",
    "        return rectangle\n",
    "    \n",
    "    def warp_perspective(self, image):\n",
    "        \n",
    "        rect = self.get_rectangle()\n",
    "        (tl, tr, br, bl) = rect\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "        dst = np.array([[0, 0], [maxWidth-1, 0], [maxWidth-1, maxHeight-1],\n",
    "            [0, maxHeight-1]], dtype = \"float32\")\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "        \n",
    "        return warped    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = input_image.copy()\n",
    "warping = PerspectiveTransform(points)\n",
    "final_output = warping.warp_perspective(image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = input_image.copy()\n",
    "\n",
    "fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(corner_detector.visualize_corner_points(img, points, 26))\n",
    "plt.title(\"Corner Points Detected\")\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1, 2,2)\n",
    "plt.imshow(cv2.resize(final_output, (700, 950)))\n",
    "plt.title(\"Tilt Corrected Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Visualization of All Stages </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all(stage, row_size, column_size):\n",
    "    \"\"\"This function takes all six stage images along with input image packed in a tupel\n",
    "    and display them with proper labeling\"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize = (row_size, column_size))\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, 1)\n",
    "    plt.imshow(stage[0])\n",
    "    plt.title(\"INPUT Image\")\n",
    "    plt.axis('Off')\n",
    "\n",
    "    ax = fig.add_subplot(2, 3,2)\n",
    "    plt.imshow(stage[1], cmap = 'gray')\n",
    "    plt.title(\"STAGE 1 : Gray Scaled Image\")\n",
    "    plt.axis('Off')\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, 3)\n",
    "    plt.imshow(stage[2], cmap = 'gray')\n",
    "    plt.title(\"STAGE 2 :Gaussian Blurred Image\")\n",
    "    plt.axis('Off')\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(2, 3,4)\n",
    "    plt.imshow(stage[3], cmap = 'gray')\n",
    "    plt.title(\"STAGE 3 : Edge Detection : Canny Operator\")\n",
    "    plt.axis('Off')\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, 5)\n",
    "    plt.imshow(stage[4], cmap = 'gray')\n",
    "    plt.title(\"STAGE 4 : Line Detection : Hough Transform\")\n",
    "    plt.axis('Off')\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(2, 3, 6)\n",
    "    plt.imshow(stage[5])\n",
    "    plt.title(\"STAGE 5 : Corner Points Detection\")\n",
    "    plt.axis('Off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    # ax = fig.add_subplot(4, 2, 7)\n",
    "    plt.imshow(stage[6])\n",
    "    plt.title(\"STAGE 6 : Perspective Transform : OUTPUT\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./data/out.png', bbox_inches = 'tight')    \n",
    "    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packing all stage images in a tuple.\n",
    "prime_demo = (input_image, gray, filtered_image,\n",
    "              edges, hough_lines, plot_corner_points, cv2.resize(final_output, (700, 950)))\n",
    "\n",
    "\n",
    "show_all(prime_demo, 20, 17)     # displaying them all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Experiments: </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this modeule takes tilted input image and returns all the stages of tilt correction.\n",
    "from tilt_correction import stage_wise_tilt_correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test Case 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image1 = np.array(Image.open('./data/test_case1.jpeg')) # reading the input image\n",
    "result1 = stage_wise_tilt_correction(test_image1)\n",
    "show_all(result1, 20, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test Case 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image2 = np.array(Image.open('./data/test_case2.jpeg')) # reading the input image\n",
    "result2 = stage_wise_tilt_correction(test_image2)\n",
    "show_all(result2, 20, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test Case 3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image3 = np.array(Image.open('./data/test_case3.jpeg')) # reading the input image\n",
    "result3 = stage_wise_tilt_correction(test_image3)\n",
    "show_all(result3, 20, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test Case 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image4 = np.array(Image.open('./data/test_case4.jpeg')) # reading the input image\n",
    "result4 = stage_wise_tilt_correction(test_image4)\n",
    "show_all(result4, 15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test Case 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image5 = np.array(Image.open('./data/test_case5.jpeg')) # reading the input image\n",
    "result5 = stage_wise_tilt_correction(test_image5)\n",
    "show_all(result5, 15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test Case 6 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image6 = np.array(Image.open('./data/test_case6.jpeg')) # reading the input image\n",
    "result6 = stage_wise_tilt_correction(test_image6)\n",
    "show_all(result6, 15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Saving the figures for report </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (12, 15))\n",
    "\n",
    "# ax = fig.add_subplot(2, 2, 1)\n",
    "# plt.imshow(result6[0])\n",
    "# plt.title('INPUT Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# ax = fig.add_subplot(2, 2,2)\n",
    "# plt.imshow(result6[3], cmap = 'gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# ax = fig.add_subplot(2, 2,3)\n",
    "# plt.imshow(result6[5])\n",
    "# plt.axis('off')\n",
    "\n",
    "# ax = fig.add_subplot(2, 2,4)\n",
    "# plt.imshow(result6[6])\n",
    "# plt.title('OUPUT Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "\n",
    "# plt.savefig('./data/report_fig/case6.png', bbox_inches = 'tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
